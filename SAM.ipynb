{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cvx\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.covariance import LedoitWolf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading historical prices\n",
    "\n",
    "Both close and open prices are used. Trading is done at open based on close prices. The trading universe consists of the 50 largest publicly traded companies in Sweden. If yfinance messes around, just download from google colab and export to .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  2 of 2 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "['ATCO-B.ST', 'INVE-B.ST']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n",
      "[*********************100%***********************]  2 of 2 completed\n",
      "\n",
      "2 Failed downloads:\n",
      "['ATCO-B.ST', 'INVE-B.ST']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "tickers = [\n",
    "    'INVE-B.ST', 'ATCO-B.ST', 'VOLV-B.ST', 'ASSA-B.ST', 'EQT.ST',\n",
    "    'SEB-A.ST', 'ERIC-B.ST', 'HEXA-B.ST', 'SAND.ST', 'HM-B.ST',\n",
    "    'SWED-A.ST', 'EPI-A.ST', 'SHB-A.ST', 'ESSITY-B.ST', 'ALFA.ST',\n",
    "    'EVO.ST', 'LATO-B.ST', 'INDU-A.ST', 'LIFCO-B.ST',\n",
    "    'LUND-B.ST', 'SAAB-B.ST', 'TELIA.ST', 'AKEL-D.ST',\n",
    "    'SOBI.ST', 'INDT.ST', 'SCA-B.ST', 'SKF-B.ST', 'SKA-B.ST',\n",
    "    'BEIJ-B.ST', 'ALIV-SDB.ST', 'SAVE.ST', 'HOLM-B.ST', 'AAK.ST',\n",
    "    'SWEC-B.ST', 'SECT-B.ST', 'SSAB-B.ST', 'AXFO.ST', 'GETI-B.ST',\n",
    "    'SAGA-B.ST', 'VOLCAR-B.ST', 'NDA-SE.ST', 'KINV-B.ST', 'BOL.ST',\n",
    "    'FABG.ST', 'BALD-B.ST', 'CAST.ST', 'PEAB-B.ST', 'NCC-B.ST'\n",
    "]\n",
    "\n",
    "tickers = [\n",
    "    'INVE-B.ST', 'ATCO-B.ST', 'VOLV-B.ST', 'ASSA-B.ST',\n",
    "    'SEB-A.ST']\n",
    "\"\"\"\n",
    "# Analysis period, can easily be changed\n",
    "start_date = \"2010-01-01\"\n",
    "end_date = \"2025-05-23\"\n",
    "\n",
    "# Download historical opening and closing prices\n",
    "price_close = yf.download(tickers, start=start_date, end=end_date)['Close']\n",
    "price_open = yf.download(tickers, start=start_date, end=end_date)['Open']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Downloads from csv files ###\n",
    "\n",
    "price_close = pd.read_csv('price_close.csv')\n",
    "price_open = pd.read_csv('price_open.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple code for handling stocks with insufficient amount of historical data, probably more than enough.   \n",
    "def create_window_and_valid_tickers(returns, current_date):\n",
    "    window = returns.loc[current_date - pd.DateOffset(years=4):current_date]\n",
    "    valid_data = window.dropna(axis=1)  # remove stocks with any missing values\n",
    "    return valid_data\n",
    "\n",
    "\"\"\"\n",
    "    GPT generated code for analyzing gaps in historical prices.\n",
    "\"\"\"\n",
    "# This function might be overkill\n",
    "def analyze_return_gaps(price_df):\n",
    "    summary = {}\n",
    "\n",
    "    for ticker in price_df.columns:\n",
    "        series = price_df[ticker]\n",
    "        first_valid = series.first_valid_index()\n",
    "        post_ipo_series = series.loc[first_valid:]\n",
    "        missing = post_ipo_series.isna()\n",
    "\n",
    "        gap_lengths = []\n",
    "        current_gap = 0\n",
    "\n",
    "        for val in missing:\n",
    "            if val:\n",
    "                current_gap += 1\n",
    "            elif current_gap > 0:\n",
    "                gap_lengths.append(current_gap)\n",
    "                current_gap = 0\n",
    "\n",
    "        # If gap at end\n",
    "        if current_gap > 0:\n",
    "            gap_lengths.append(current_gap)\n",
    "\n",
    "        summary[ticker] = {\n",
    "            'first_valid': first_valid,\n",
    "            'total_days': len(post_ipo_series),\n",
    "            'missing_days': missing.sum(),\n",
    "            'missing_pct': 100 * missing.sum() / len(post_ipo_series),\n",
    "            'gap_count': len(gap_lengths),\n",
    "            'max_gap': max(gap_lengths) if gap_lengths else 0,\n",
    "            'avg_gap': sum(gap_lengths) / len(gap_lengths) if gap_lengths else 0\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(summary).T.sort_values(by='missing_pct', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance matrix \n",
    "\n",
    "The next section handles estimation of covariance matrices used for the portfolio optimization.\n",
    "Will include;  \n",
    "\n",
    "1. Sample covariance with .cov() method.  \n",
    "\n",
    "2. Sample covariance with Ledoit-Wolff shrinkage model from scikit-learn.  \n",
    "\n",
    "3. EWMA based covariance matrix.  \n",
    "\n",
    "When estimating covariance matrices, returns should be filtered so that they contain enough historical values without large gaps. For this implementation, 2 years of data will be used to estimate covariance matrices, stocks with >5% missing values will be dropped for EWMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_covariance(returns):\n",
    "\n",
    "    return returns.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ledoit_wolff_covariance(returns):\n",
    "    \n",
    "    model = LedoitWolf()\n",
    "    cov_matrix = model.fit(returns).covariance_\n",
    "    return cov_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewma_covariance(returns):\n",
    "    \n",
    "    lambda_ = 0.94\n",
    "    # Initialize the covariance matrix (using the first row of returns)\n",
    "    cov_matrix = returns.iloc[0].to_frame().dot(returns.iloc[0].to_frame().T)\n",
    "    \n",
    "    # Iteratively calculate EWMA covariance\n",
    "    for t in range(1, len(returns)):\n",
    "        r_t = returns.iloc[t].to_frame()\n",
    "        cov_matrix = lambda_ * cov_matrix + (1 - lambda_) * r_t.dot(r_t.T)\n",
    "    \n",
    "    return cov_matrix.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Optimization\n",
    "\n",
    "In the next section, portfolio optimization models are implemented.  \n",
    "Models include;  \n",
    "\n",
    "1. Markowitz Mean-Variance  \n",
    "\n",
    "2. Markowitz Minimum-Variance\n",
    "\n",
    "3. ERC - Equal Risk Contributions  \n",
    "\n",
    "4. HRP - Hiearchical Risk Parity   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markowitz minimum variance\n",
    "\n",
    "def markowitz_min_variance(returns, cov_func):\n",
    "\n",
    "    n = returns.shape[1]\n",
    "    sigma = cov_func(returns)\n",
    "    w = cvx.Variable(n)\n",
    "    portfolio_risk = cvx.quad_form(w, sigma)\n",
    "\n",
    "    objective = cvx.Minimize(portfolio_risk)\n",
    "    constraints = [cvx.sum(w) == 1, w >= 0]\n",
    "    problem = cvx.Problem(objective, constraints)\n",
    "    problem.solve(solver=cvx.ECOS)\n",
    "\n",
    "    return pd.Series(w.value, index = returns.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERC - Equal Risk Contribution\n",
    "\n",
    "def risk_contribution(weights, cov):\n",
    "    portfolio_var = weights.T @ cov @ weights\n",
    "    sigma = np.sqrt(portfolio_var)\n",
    "    mrc = cov @ weights\n",
    "    rc = weights * mrc\n",
    "    return rc / sigma\n",
    "\n",
    "def objective(weights, cov):\n",
    "    rc = risk_contribution(weights, cov)\n",
    "    target = np.mean(rc)\n",
    "    return np.sum((rc - target)**2)\n",
    "\n",
    "def equal_risk_portfolio(returns, cov_func):\n",
    "    cov = cov_func(returns)\n",
    "    n = cov.shape[0]\n",
    "    x0 = np.ones(n) / n\n",
    "    bounds = [(0, 1) for _ in range(n)]\n",
    "    constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]\n",
    "    \n",
    "    result = minimize(objective, x0, args=(cov,), method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return pd.Series(result.x, index=returns.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Risk Parity\n",
    "\n",
    "#########################\n",
    "#   Three stages:\n",
    "#\n",
    "#   1. Tree clustering\n",
    "#   2. Quasi-diagonalization\n",
    "#   3. Recursive bisection\n",
    "#\n",
    "#########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1-Filter\n",
    "\n",
    "L1-filter, as presented by X (20XX), is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_trend_filter(y, lam):\n",
    "    n = len(y)\n",
    "    x = cvx.Variable(n)\n",
    "    objective = cvx.Minimize(0.5 * cvx.sum_squares(y - x) + lam * cvx.norm1(cvx.diff(x, 2)))\n",
    "    prob = cvx.Problem(objective)\n",
    "    prob.solve()\n",
    "    return np.array(x.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
