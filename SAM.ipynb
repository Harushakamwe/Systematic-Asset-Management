{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.covariance import LedoitWolf\n",
    "import cvxpy as cvx\n",
    "from scipy.optimize import minimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  5 of 5 completed\n",
      "[*********************100%***********************]  5 of 5 completed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Downloading historical opening and closing prices for the equities. Open and Close is used since trading is done by buying at open and selling as close to close as possible. For this reason, returns will be calculated in a way that reflects this rule.\n",
    "\"\"\"\n",
    "# 48 largest companies in Sweden\n",
    "\"\"\"\n",
    "tickers = [\n",
    "    'INVE-B.ST', 'ATCO-B.ST', 'VOLV-B.ST', 'ASSA-B.ST', 'EQT.ST',\n",
    "    'SEB-A.ST', 'ERIC-B.ST', 'HEXA-B.ST', 'SAND.ST', 'HM-B.ST',\n",
    "    'SWED-A.ST', 'EPI-A.ST', 'SHB-A.ST', 'ESSITY-B.ST', 'ALFA.ST',\n",
    "    'EVO.ST', 'LATO-B.ST', 'INDU-A.ST', 'LIFCO-B.ST',\n",
    "    'LUND-B.ST', 'SAAB-B.ST', 'TELIA.ST', 'AKEL-D.ST',\n",
    "    'SOBI.ST', 'INDT.ST', 'SCA-B.ST', 'SKF-B.ST', 'SKA-B.ST',\n",
    "    'BEIJ-B.ST', 'ALIV-SDB.ST', 'SAVE.ST', 'HOLM-B.ST', 'AAK.ST',\n",
    "    'SWEC-B.ST', 'SECT-B.ST', 'SSAB-B.ST', 'AXFO.ST', 'GETI-B.ST',\n",
    "    'SAGA-B.ST', 'VOLCAR-B.ST', 'NDA-SE.ST', 'KINV-B.ST', 'BOL.ST',\n",
    "    'FABG.ST', 'BALD-B.ST', 'CAST.ST', 'PEAB-B.ST', 'NCC-B.ST'\n",
    "]\n",
    "\"\"\"\n",
    "tickers = [\n",
    "    'INVE-B.ST', 'ATCO-B.ST', 'VOLV-B.ST', 'ASSA-B.ST',\n",
    "    'SEB-A.ST']\n",
    "\n",
    "# Analysis period, can easily be changed\n",
    "start_date = \"2010-01-01\"\n",
    "end_date = \"2025-05-23\"\n",
    "\n",
    "# Download historical opening and closing prices\n",
    "price_close = yf.download(tickers, start=start_date, end=end_date)['Close']\n",
    "price_open = yf.download(tickers, start=start_date, end=end_date)['Open']\n",
    "\n",
    "# Calculation of historical returns for closing prices and a intraday intepolation of prices.\n",
    "simple_returns_close = price_close[tickers].pct_change()\n",
    "log_returns_close = np.log(price_open / price_open.shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple code for handling stocks with insufficient amount of historical data, probably more than enough.   \n",
    "def create_window_and_valid_tickers(returns, current_date):\n",
    "    window = returns.loc[current_date - pd.DateOffset(years=4):current_date]\n",
    "    valid_data = window.dropna(axis=1)  # remove stocks with any missing values\n",
    "    return valid_data\n",
    "\n",
    "\"\"\"\n",
    "    GPT generated code for analyzing gaps in historical prices.\n",
    "\"\"\"\n",
    "# This function might be overkill\n",
    "def analyze_return_gaps(price_df):\n",
    "    summary = {}\n",
    "\n",
    "    for ticker in price_df.columns:\n",
    "        series = price_df[ticker]\n",
    "        first_valid = series.first_valid_index()\n",
    "        post_ipo_series = series.loc[first_valid:]\n",
    "        missing = post_ipo_series.isna()\n",
    "\n",
    "        gap_lengths = []\n",
    "        current_gap = 0\n",
    "\n",
    "        for val in missing:\n",
    "            if val:\n",
    "                current_gap += 1\n",
    "            elif current_gap > 0:\n",
    "                gap_lengths.append(current_gap)\n",
    "                current_gap = 0\n",
    "\n",
    "        # If gap at end\n",
    "        if current_gap > 0:\n",
    "            gap_lengths.append(current_gap)\n",
    "\n",
    "        summary[ticker] = {\n",
    "            'first_valid': first_valid,\n",
    "            'total_days': len(post_ipo_series),\n",
    "            'missing_days': missing.sum(),\n",
    "            'missing_pct': 100 * missing.sum() / len(post_ipo_series),\n",
    "            'gap_count': len(gap_lengths),\n",
    "            'max_gap': max(gap_lengths) if gap_lengths else 0,\n",
    "            'avg_gap': sum(gap_lengths) / len(gap_lengths) if gap_lengths else 0\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(summary).T.sort_values(by='missing_pct', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    This section handles the different covariance models. Will include;\n",
    "    1.) Sample covariance with .cov() method, implemented directly in the portfolio optimization methods\n",
    "    2.) Sample covariance with Ledoit-Wolff Shrinkage model from sklearn\n",
    "    3.) EWMA based covariance matrix\n",
    "    4.) DCC-GARCH based covariance matrix\n",
    "\n",
    "    For the estimation of covariance matrices, returns should be filtered so that they contain enough historical values. For this implementation, 4 years of data will be used to estimate covariance matrices, stocks with >5% missing values will be dropped for EWMA and >1% for DCC-GARCH.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ledoit_wolff_covariance(returns):\n",
    "    model = LedoitWolf()\n",
    "    cov_matrix = model.fit(returns).covariance_\n",
    "    return cov_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewma_covariance(returns):\n",
    "    lambda_ = 0.94\n",
    "    # Initialize the covariance matrix (using the first row of returns)\n",
    "    cov_matrix = returns.iloc[0].to_frame().dot(returns.iloc[0].to_frame().T)\n",
    "    \n",
    "    # Iteratively calculate EWMA covariance\n",
    "    for t in range(1, len(returns)):\n",
    "        r_t = returns.iloc[t].to_frame()\n",
    "        cov_matrix = lambda_ * cov_matrix + (1 - lambda_) * r_t.dot(r_t.T)\n",
    "    \n",
    "    return cov_matrix.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create DCC-GARCH method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Portfolio optimization models.\n",
    "\n",
    "    1.) Markowitz min variance\n",
    "    2.) ERC - Equal Risk Contributions\n",
    "    3.) HRP - Hiearchical Risk Parity\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markowitz minimum variance\n",
    "\n",
    "def markowitz_min_variance(returns, cov_func):\n",
    "\n",
    "    n = returns.shape[1]\n",
    "    sigma = cov_func(returns)\n",
    "    w = cvx.Variable(n)\n",
    "    portfolio_risk = cvx.quad_form(w, sigma)\n",
    "\n",
    "    objective = cvx.Minimize(portfolio_risk)\n",
    "    constraints = [cvx.sum(w) == 1, w >= 0]\n",
    "    problem = cvx.Problem(objective, constraints)\n",
    "    problem.solve(solver=cvx.ECOS)\n",
    "\n",
    "    return pd.Series(w.value, index = returns.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERC - Equal Risk Contribution\n",
    "\n",
    "def risk_contribution(weights, cov):\n",
    "    portfolio_var = weights.T @ cov @ weights\n",
    "    sigma = np.sqrt(portfolio_var)\n",
    "    mrc = cov @ weights\n",
    "    rc = weights * mrc\n",
    "    return rc / sigma\n",
    "\n",
    "def objective(weights, cov):\n",
    "    rc = risk_contribution(weights, cov)\n",
    "    target = np.mean(rc)\n",
    "    return np.sum((rc - target)**2)\n",
    "\n",
    "def equal_risk_portfolio(returns, cov_func):\n",
    "    cov = cov_func(returns)\n",
    "    n = cov.shape[0]\n",
    "    x0 = np.ones(n) / n\n",
    "    bounds = [(0, 1) for _ in range(n)]\n",
    "    constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]\n",
    "    \n",
    "    result = minimize(objective, x0, args=(cov,), method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return pd.Series(result.x, index=returns.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
